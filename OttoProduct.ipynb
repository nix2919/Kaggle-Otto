{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "data = read_csv(\"train.csv\")\n",
    "\n",
    "# Test data\n",
    "test = read_csv(\"test.csv\")\n",
    "test = test.loc[:, 'feat_1':'feat_93']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0   1       1       0       0       0       0       0       0       0       0   \n",
       "1   2       0       0       0       0       0       0       0       1       0   \n",
       "\n",
       "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
       "0   ...           1        0        0        0        0        0        0   \n",
       "1   ...           0        0        0        0        0        0        0   \n",
       "\n",
       "   feat_92  feat_93   target  \n",
       "0        0        0  Class_1  \n",
       "1        0        0  Class_1  \n",
       "\n",
       "[2 rows x 95 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying target from \"Class_1\" to \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['target'] = data['target'].apply(lambda x: int(x.split('_')[1]))\n",
    "# Drop the \"ID\" column\n",
    "train = data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "0       1       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       1       0   \n",
      "\n",
      "   feat_10   ...     feat_84  feat_85  feat_86  feat_87  feat_88  feat_89  \\\n",
      "0        0   ...           0        1        0        0        0        0   \n",
      "1        0   ...           0        0        0        0        0        0   \n",
      "\n",
      "   feat_90  feat_91  feat_92  feat_93  \n",
      "0        0        0        0        0  \n",
      "1        0        0        0        0  \n",
      "\n",
      "[2 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "X = train.loc[:, :'feat_93']\n",
    "y = train['target']\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_xgb_org' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-708b12ea6e66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest_xgb_org\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_xgb_org\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtest_xgb_org\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtest_xgb_org\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_xgb_org' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26781    4\n",
       "44888    6\n",
       "60049    9\n",
       "56633    8\n",
       "34223    6\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 2    16122\n",
      "6    14135\n",
      "8     8464\n",
      "3     8004\n",
      "9     4955\n",
      "7     2839\n",
      "5     2739\n",
      "4     2691\n",
      "1     1929\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Target Class\\n', train['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feat_1     0\n",
       "feat_2     0\n",
       "feat_3     0\n",
       "feat_4     0\n",
       "feat_5     0\n",
       "feat_6     0\n",
       "feat_7     0\n",
       "feat_8     0\n",
       "feat_9     0\n",
       "feat_10    0\n",
       "feat_11    0\n",
       "feat_12    0\n",
       "feat_13    0\n",
       "feat_14    0\n",
       "feat_15    0\n",
       "feat_16    0\n",
       "feat_17    0\n",
       "feat_18    0\n",
       "feat_19    0\n",
       "feat_20    0\n",
       "feat_21    0\n",
       "feat_22    0\n",
       "feat_23    0\n",
       "feat_24    0\n",
       "feat_25    0\n",
       "feat_26    0\n",
       "feat_27    0\n",
       "feat_28    0\n",
       "feat_29    0\n",
       "feat_30    0\n",
       "          ..\n",
       "feat_64    0\n",
       "feat_65    0\n",
       "feat_66    0\n",
       "feat_67    0\n",
       "feat_68    0\n",
       "feat_69    0\n",
       "feat_70    0\n",
       "feat_71    0\n",
       "feat_72    0\n",
       "feat_73    0\n",
       "feat_74    0\n",
       "feat_75    0\n",
       "feat_76    0\n",
       "feat_77    0\n",
       "feat_78    0\n",
       "feat_79    0\n",
       "feat_80    0\n",
       "feat_81    0\n",
       "feat_82    0\n",
       "feat_83    0\n",
       "feat_84    0\n",
       "feat_85    0\n",
       "feat_86    0\n",
       "feat_87    0\n",
       "feat_88    0\n",
       "feat_89    0\n",
       "feat_90    0\n",
       "feat_91    0\n",
       "feat_92    0\n",
       "feat_93    0\n",
       "Length: 93, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing value check\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "X_train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import var, count_nonzero\n",
    "\n",
    "def agg_feat(data):\n",
    "    data['sum'] = data.apply(lambda row: sum(row.values), axis=1)\n",
    "    data['var'] = data.apply(lambda row: var(row.values), axis=1)\n",
    "    data['nonzero'] = data.apply(lambda row: count_nonzero(row.values), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = agg_feat(X_train)\n",
    "X_test = agg_feat(X_test)\n",
    "test = agg_feat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>sum</th>\n",
       "      <th>var</th>\n",
       "      <th>nonzero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>44.251698</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>160.800362</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       2       2      14      16       0       0       0       0       0   \n",
       "\n",
       "   feat_10   ...     feat_87  feat_88  feat_89  feat_90  feat_91  feat_92  \\\n",
       "0        3   ...           1       20        0        0        0        0   \n",
       "1        0   ...           0        0        4        0        0        2   \n",
       "\n",
       "   feat_93  sum         var  nonzero  \n",
       "0        0   61   44.251698       21  \n",
       "1        0  120  160.800362       24  \n",
       "\n",
       "[2 rows x 96 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = list(X_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = X_train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_39 feat_45 0.81029272183\n",
      "sum var 0.893935738917\n",
      "sum nonzero 0.839892825355\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.8) and (curr_cor < 0.9):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(X_train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(norm_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(norm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAIACAYAAADXBtIGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGOMMZ3hhaAxxhhjjDHGdMbf17ceThFkBvcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c3a82ffba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp[:30].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(15,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feat_34', 'feat_11', 'feat_60', 'var', 'feat_40', 'feat_14', 'feat_25', 'feat_26', 'sum', 'nonzero', 'feat_15', 'feat_67', 'feat_42', 'feat_86', 'feat_90', 'feat_36', 'feat_62', 'feat_48', 'feat_24', 'feat_75', 'feat_69', 'feat_88', 'feat_8', 'feat_72', 'feat_64', 'feat_43', 'feat_27', 'feat_32', 'feat_9', 'feat_68']\n"
     ]
    }
   ],
   "source": [
    "imp_feats = list(feat_imp[:30].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[imp_feats]\n",
    "X_train = X_train[imp_feats]\n",
    "X_test = X_test[imp_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline_params():\n",
    "    rf = RandomForestClassifier()\n",
    "    et = ExtraTreesClassifier()\n",
    "    ada = AdaBoostClassifier(base_estimator=et)\n",
    "    xg = xgb.XGBClassifier(objective='multi:softprob')\n",
    "    gb = GradientBoostingClassifier()\n",
    "    lr = LogisticRegression()\n",
    "    rfe = RFE(rf, step=0.2)\n",
    "    select = SelectFromModel(rf)\n",
    "    kbest = SelectKBest(chi2)\n",
    "    pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "    feat_sel_params = [\n",
    "        {\n",
    "            'feat_sel': [kbest],\n",
    "            'feat_sel__k': [30]},\n",
    "        {\n",
    "            'feat_sel': [rfe],\n",
    "            'feat_sel__estimator': [rf], #rf, et, gb, xg\n",
    "            'feat_sel__n_features_to_select': [30]},\n",
    "        {\n",
    "            'feat_sel': [select],\n",
    "            'feat_sel__estimator': [rf]} #rf, et, gb, xg\n",
    "    ]\n",
    "    model_params = [\n",
    "        {\n",
    "            'model': [gb],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__learning_rate': [0.1]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "#         {\n",
    "#             'model': [ada],\n",
    "#             'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "#             'model__learning_rate': [0.03], #0.01, 0.04, 0.1, 0.5, 1\n",
    "#             'model__random_state': [9]},\n",
    "        {\n",
    "            'model': [xg],\n",
    "            'model__objective': ['multi:softprob'],\n",
    "            'model__learning_rate': [0.1],   # Learning rate alpha\n",
    "            'model__gamma': [0.1],   # minimum eval_score deduction at each split\n",
    "            'model__min_child_weight': [4],  # minimum number of datapoints in a split\n",
    "            'model__subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "            'model__colsample_bytree': [0.7],  # column-wise sample size\n",
    "            'model__n_estimators': [100]},   # number of trees to build\n",
    "        {\n",
    "            'model': [rf],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__criterion': ['gini', 'entropy'],\n",
    "            'model__max_features': ['sqrt'], #, 'log2'\n",
    "            'model__min_samples_leaf': [4], #3, 5, 7, 9\n",
    "            'model__max_depth': [11]}, #8, 10, 14\n",
    "        {\n",
    "            'model': [et],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__criterion': ['gini', 'entropy'],\n",
    "            'model__max_features': ['sqrt'], #, 'log2'\n",
    "            'model__min_samples_leaf': [4], #3, 5, 7\n",
    "            'model__max_depth': [11]} #8, 10, 14\n",
    "    ]\n",
    "    params = []\n",
    "    for feat_sel in feat_sel_params:\n",
    "        for model in model_params:\n",
    "            # Merge dictionaries and append to list\n",
    "            params.append({**feat_sel, **model})\n",
    "    return pipe, feat_sel_params, model_params, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe, feat_params, model_params, all_params = pipeline_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002C3A07E5B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002C3A07E5B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 17, 48, 13, 248589, tzinfo=tzutc()), 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'session': '5C9DC171AD984C6682DEB7412202F054', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'5C9DC171AD984C6682DEB7412202F054']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 17, 48, 13, 248589, tzinfo=tzutc()), 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'session': '5C9DC171AD984C6682DEB7412202F054', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'5C9DC171AD984C6682DEB7412202F054'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 17, 48, 13, 248589, tzinfo=tzutc()), 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'session': '5C9DC171AD984C6682DEB7412202F054', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-71-5ddff90266fd>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2c3b46880f0, executio..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002C3A8032420, file \"<ipython-input-71-5ddff90266fd>\", line 2>\n        result = <ExecutionResult object at 2c3b46880f0, executio..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002C3A8032420, file \"<ipython-input-71-5ddff90266fd>\", line 2>, result=<ExecutionResult object at 2c3b46880f0, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002C3A8032420, file \"<ipython-input-71-5ddff90266fd>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Test data\\ntest = read_csv(\"test.csv\")', 'data.head(2)', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", r\"print('Target Class\\n', train['target'].value_counts())\", '# Missing value check\\nX_train.isnull().sum()', '# Splitting Train test\\nX_train, X_test, y_train,...X, y, stratify=y, test_size=0.3, random_state=12)', 'y_test.head(2)', '# Missing value check\\nX_train.isnull().sum()', 'from numpy import var, count_nonzero\\n\\ndef agg_fe...ount_nonzero(row.values), axis=1)\\n    return data', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", '# Normalization of Train and Test\\ncols = list(X....\\ntest_xgb_org.columns = cols\\ntest_xgb_org.head(2)', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {4:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 10: 26781    4\n44888    6\nName: target, dtype: int64, 11: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 20:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 24: 26781    4\n44888    6\nName: target, dtype: int64, 26: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 29:    feat_1  feat_2  feat_3  feat_4  feat_5  feat_...120  160.800362       24  \n\n[2 rows x 96 columns], 34: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 44: array([3, 6, 4, 2, 1, 7, 5, 8, 9], dtype=int64), 52:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], ...}, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Test data\\ntest = read_csv(\"test.csv\")', 'data.head(2)', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", r\"print('Target Class\\n', train['target'].value_counts())\", '# Missing value check\\nX_train.isnull().sum()', '# Splitting Train test\\nX_train, X_test, y_train,...X, y, stratify=y, test_size=0.3, random_state=12)', 'y_test.head(2)', '# Missing value check\\nX_train.isnull().sum()', 'from numpy import var, count_nonzero\\n\\ndef agg_fe...ount_nonzero(row.values), axis=1)\\n    return data', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", '# Normalization of Train and Test\\ncols = list(X....\\ntest_xgb_org.columns = cols\\ntest_xgb_org.head(2)', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {4:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 10: 26781    4\n44888    6\nName: target, dtype: int64, 11: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 20:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 24: 26781    4\n44888    6\nName: target, dtype: int64, 26: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 29:    feat_1  feat_2  feat_3  feat_4  feat_5  feat_...120  160.800362       24  \n\n[2 rows x 96 columns], 34: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 44: array([3, 6, 4, 2, 1, 7, 5, 8, 9], dtype=int64), 52:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], ...}, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\nikhi\\Desktop\\Practice\\Kaggle-Otto\\<ipython-input-71-5ddff90266fd> in <module>()\n      1 grid = GridSearchCV(estimator=pipe, param_grid=all_params, scoring=make_scorer(log_loss), verbose=20, n_jobs=-1)\n----> 2 grid.fit(X_train, y_train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...       scoring=make_scorer(log_loss), verbose=20), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], y=24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns]\n        y = 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Apr  9 23:20:04 2018\nPID: 11184                Python 3.6.3: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], y=24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, scorer={'score': make_scorer(log_loss)}, train=array([14090, 14097, 14160, ..., 43311, 43312, 43313]), test=array([    0,     1,     2, ..., 14606, 14609, 14616]), verbose=20, parameters={'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorer={'score': make_scorer(log_loss)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorers={'score': make_scorer(log_loss)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(log_loss)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(log_loss), estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py in log_loss(y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, y_pred=array([[  9.99200722e-16,   1.00000000e+00],\n   ...0],\n       [  9.99200722e-16,   1.00000000e+00]]), eps=1e-15, normalize=True, sample_weight=None, labels=None)\n   1681                              \"classes {0}, {1}. Please provide the true \"\n   1682                              \"labels explicitly through the labels argument. \"\n   1683                              \"Classes found in \"\n   1684                              \"y_true: {2}\".format(transformed_labels.shape[1],\n   1685                                                   y_pred.shape[1],\n-> 1686                                                   lb.classes_))\n        lb.classes_ = array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n   1687         else:\n   1688             raise ValueError('The number of classes in labels is different '\n   1689                              'from that in y_pred. Classes found in '\n   1690                              'labels: {0}'.format(lb.classes_))\n\nValueError: y_true and y_pred contain different number of classes 9, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [1 2 3 4 5 6 7 8 9]\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 488, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 523, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 553, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 108, in __call__\n    **self._kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\", line 1686, in log_loss\n    lb.classes_))\nValueError: y_true and y_pred contain different number of classes 9, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [1 2 3 4 5 6 7 8 9]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Apr  9 23:20:04 2018\nPID: 11184                Python 3.6.3: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], y=24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, scorer={'score': make_scorer(log_loss)}, train=array([14090, 14097, 14160, ..., 43311, 43312, 43313]), test=array([    0,     1,     2, ..., 14606, 14609, 14616]), verbose=20, parameters={'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorer={'score': make_scorer(log_loss)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorers={'score': make_scorer(log_loss)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(log_loss)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(log_loss), estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py in log_loss(y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, y_pred=array([[  9.99200722e-16,   1.00000000e+00],\n   ...0],\n       [  9.99200722e-16,   1.00000000e+00]]), eps=1e-15, normalize=True, sample_weight=None, labels=None)\n   1681                              \"classes {0}, {1}. Please provide the true \"\n   1682                              \"labels explicitly through the labels argument. \"\n   1683                              \"Classes found in \"\n   1684                              \"y_true: {2}\".format(transformed_labels.shape[1],\n   1685                                                   y_pred.shape[1],\n-> 1686                                                   lb.classes_))\n        lb.classes_ = array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n   1687         else:\n   1688             raise ValueError('The number of classes in labels is different '\n   1689                              'from that in y_pred. Classes found in '\n   1690                              'labels: {0}'.format(lb.classes_))\n\nValueError: y_true and y_pred contain different number of classes 9, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [1 2 3 4 5 6 7 8 9]\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Apr  9 23:20:04 2018\nPID: 11184                Python 3.6.3: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], y=24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, scorer={'score': make_scorer(log_loss)}, train=array([14090, 14097, 14160, ..., 43311, 43312, 43313]), test=array([    0,     1,     2, ..., 14606, 14609, 14616]), verbose=20, parameters={'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorer={'score': make_scorer(log_loss)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorers={'score': make_scorer(log_loss)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(log_loss)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(log_loss), estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py in log_loss(y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, y_pred=array([[  9.99200722e-16,   1.00000000e+00],\n   ...0],\n       [  9.99200722e-16,   1.00000000e+00]]), eps=1e-15, normalize=True, sample_weight=None, labels=None)\n   1681                              \"classes {0}, {1}. Please provide the true \"\n   1682                              \"labels explicitly through the labels argument. \"\n   1683                              \"Classes found in \"\n   1684                              \"y_true: {2}\".format(transformed_labels.shape[1],\n   1685                                                   y_pred.shape[1],\n-> 1686                                                   lb.classes_))\n        lb.classes_ = array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n   1687         else:\n   1688             raise ValueError('The number of classes in labels is different '\n   1689                              'from that in y_pred. Classes found in '\n   1690                              'labels: {0}'.format(lb.classes_))\n\nValueError: y_true and y_pred contain different number of classes 9, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [1 2 3 4 5 6 7 8 9]\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-5ddff90266fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002C3A07E5B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002C3A07E5B70, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 17, 48, 13, 248589, tzinfo=tzutc()), 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'session': '5C9DC171AD984C6682DEB7412202F054', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'5C9DC171AD984C6682DEB7412202F054']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 17, 48, 13, 248589, tzinfo=tzutc()), 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'session': '5C9DC171AD984C6682DEB7412202F054', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'5C9DC171AD984C6682DEB7412202F054'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 9, 17, 48, 13, 248589, tzinfo=tzutc()), 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'session': '5C9DC171AD984C6682DEB7412202F054', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '1D01D5827EEB479089ADAE70F0D6E4F1', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid = GridSearchCV(estimator=pipe, param_grid=a...verbose=20, n_jobs=-1)\\ngrid.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-71-5ddff90266fd>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2c3b46880f0, executio..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002C3A8032420, file \"<ipython-input-71-5ddff90266fd>\", line 2>\n        result = <ExecutionResult object at 2c3b46880f0, executio..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002C3A8032420, file \"<ipython-input-71-5ddff90266fd>\", line 2>, result=<ExecutionResult object at 2c3b46880f0, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002C3A8032420, file \"<ipython-input-71-5ddff90266fd>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Test data\\ntest = read_csv(\"test.csv\")', 'data.head(2)', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", r\"print('Target Class\\n', train['target'].value_counts())\", '# Missing value check\\nX_train.isnull().sum()', '# Splitting Train test\\nX_train, X_test, y_train,...X, y, stratify=y, test_size=0.3, random_state=12)', 'y_test.head(2)', '# Missing value check\\nX_train.isnull().sum()', 'from numpy import var, count_nonzero\\n\\ndef agg_fe...ount_nonzero(row.values), axis=1)\\n    return data', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", '# Normalization of Train and Test\\ncols = list(X....\\ntest_xgb_org.columns = cols\\ntest_xgb_org.head(2)', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {4:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 10: 26781    4\n44888    6\nName: target, dtype: int64, 11: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 20:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 24: 26781    4\n44888    6\nName: target, dtype: int64, 26: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 29:    feat_1  feat_2  feat_3  feat_4  feat_5  feat_...120  160.800362       24  \n\n[2 rows x 96 columns], 34: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 44: array([3, 6, 4, 2, 1, 7, 5, 8, 9], dtype=int64), 52:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], ...}, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DataFrame': <class 'pandas.core.frame.DataFrame'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Test data\\ntest = read_csv(\"test.csv\")', 'data.head(2)', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", r\"print('Target Class\\n', train['target'].value_counts())\", '# Missing value check\\nX_train.isnull().sum()', '# Splitting Train test\\nX_train, X_test, y_train,...X, y, stratify=y, test_size=0.3, random_state=12)', 'y_test.head(2)', '# Missing value check\\nX_train.isnull().sum()', 'from numpy import var, count_nonzero\\n\\ndef agg_fe...ount_nonzero(row.values), axis=1)\\n    return data', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', 'data[\\'target\\'] = data[\\'target\\'].apply(lambda x: ...p the \"ID\" column\\ntrain = data.drop(\\'id\\', axis=1)', \"X = train.loc[:, :'feat_93']\\ny = train['target']\\nprint(X.head(2))\", '# Normalization of Train and Test\\ncols = list(X....\\ntest_xgb_org.columns = cols\\ntest_xgb_org.head(2)', \"get_ipython().magic('matplotlib inline')\\nfrom pa...ction import SelectFpr, chi2, mutual_info_classif\", 'from warnings import simplefilter\\nsimplefilter(\"ignore\")', '# Train data\\ndata = read_csv(\"train.csv\")\\n\\n# Tes...test.csv\")\\ntest = test.loc[:, \\'feat_1\\':\\'feat_93\\']', ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {4:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 10: 26781    4\n44888    6\nName: target, dtype: int64, 11: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 20:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], 24: 26781    4\n44888    6\nName: target, dtype: int64, 26: feat_1     0\nfeat_2     0\nfeat_3     0\nfeat_4   ...eat_92    0\nfeat_93    0\nLength: 93, dtype: int64, 29:    feat_1  feat_2  feat_3  feat_4  feat_5  feat_...120  160.800362       24  \n\n[2 rows x 96 columns], 34: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 44: array([3, 6, 4, 2, 1, 7, 5, 8, 9], dtype=int64), 52:    id  feat_1  feat_2  feat_3  feat_4  feat_5  f...     0        0  Class_1  \n\n[2 rows x 95 columns], ...}, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\nikhi\\Desktop\\Practice\\Kaggle-Otto\\<ipython-input-71-5ddff90266fd> in <module>()\n      1 grid = GridSearchCV(estimator=pipe, param_grid=all_params, scoring=make_scorer(log_loss), verbose=20, n_jobs=-1)\n----> 2 grid.fit(X_train, y_train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...       scoring=make_scorer(log_loss), verbose=20), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], y=24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns]\n        y = 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Apr  9 23:20:04 2018\nPID: 11184                Python 3.6.3: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]),        feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], 24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, {'score': make_scorer(log_loss)}, array([14090, 14097, 14160, ..., 43311, 43312, 43313]), array([    0,     1,     2, ..., 14606, 14609, 14616]), 20, {'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...   3.203259        8  \n\n[43314 rows x 96 columns], y=24063    3\n33236    6\n27133    4\n11702    2\n2867...18    3\nName: target, Length: 43314, dtype: int64, scorer={'score': make_scorer(log_loss)}, train=array([14090, 14097, 14160, ..., 43311, 43312, 43313]), test=array([    0,     1,     2, ..., 14606, 14609, 14616]), verbose=20, parameters={'feat_sel': SelectKBest(k=30, score_func=<function chi2 at 0x00000282DDA20400>), 'feat_sel__k': 30, 'model': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'model__learning_rate': 0.1, 'model__n_estimators': 100}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorer={'score': make_scorer(log_loss)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n        scorer = {'score': make_scorer(log_loss)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X_test=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_test=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, scorers={'score': make_scorer(log_loss)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(log_loss)\n        estimator = Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))])\n        X_test =        feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns]\n        y_test = 24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(log_loss), estimator=Pipeline(memory=None,\n     steps=[('feat_sel', S....0, verbose=0,\n              warm_start=False))]), X=       feat_1  feat_2  feat_3  feat_4  feat_5  f...  12.493889       11  \n\n[14440 rows x 96 columns], y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, sample_weight=None)\n    103             return self._sign * self._score_func(y_true, y_pred,\n    104                                                  sample_weight=sample_weight,\n    105                                                  **self._kwargs)\n    106         else:\n    107             return self._sign * self._score_func(y_true, y_pred,\n--> 108                                                  **self._kwargs)\n        self._kwargs = {}\n    109 \n    110 \n    111 class _ProbaScorer(_BaseScorer):\n    112     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py in log_loss(y_true=24063    3\n33236    6\n27133    4\n11702    2\n2867...78    3\nName: target, Length: 14440, dtype: int64, y_pred=array([[  9.99200722e-16,   1.00000000e+00],\n   ...0],\n       [  9.99200722e-16,   1.00000000e+00]]), eps=1e-15, normalize=True, sample_weight=None, labels=None)\n   1681                              \"classes {0}, {1}. Please provide the true \"\n   1682                              \"labels explicitly through the labels argument. \"\n   1683                              \"Classes found in \"\n   1684                              \"y_true: {2}\".format(transformed_labels.shape[1],\n   1685                                                   y_pred.shape[1],\n-> 1686                                                   lb.classes_))\n        lb.classes_ = array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)\n   1687         else:\n   1688             raise ValueError('The number of classes in labels is different '\n   1689                              'from that in y_pred. Classes found in '\n   1690                              'labels: {0}'.format(lb.classes_))\n\nValueError: y_true and y_pred contain different number of classes 9, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [1 2 3 4 5 6 7 8 9]\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=all_params, scoring=make_scorer(log_loss), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).sort_values('rank_test_score').to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_.fit(X_train[imp_feats], y_train)\n",
    "y_pred = best_model.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.02],   # Learning rate alpha\n",
    "    'max_depth': [10],   # maximum depth of the tree\n",
    "    'gamma': [1],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.4],  # column-wise sample size\n",
    "    'n_estimators': [1000],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5, verbose=20, n_jobs=-1, refit=True)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "pred = grid.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, pred))\n",
    "print('MCC:', matthews_corrcoef(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'multi:softprob', \n",
    "    'eval_metric': 'mlogloss', \n",
    "    'num_class': 9\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "#print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
